# 1.using tips

- 前向传播通过训练数据和权重参数计算输出结果；**反向传播**通过导数链式法则计算损失函数对各参数的梯度，并根据梯度进行参数的更新
- hub：类似pytroch的model zoo，包含解决某个项目问题的完整代码、过程(预处理、构建模型、训练等)。[hub](https://pytorch.org/hub/)
- nn.functional和nn.Module：通常，模型有要学习的参数用module(卷积、全链接等)，其他用functional(激活函数、损失函数)
- Moudle类中自动实现反向传播，参数也自动初始化，所以只需定义前向传播层即可
- torchvision：datasets--读取数据并将数据构建为模型需要的datasets格式；models--一些经典的网络模型和其对应的已预训练好的参数；transforms--数据预处理
- transforms：相当于一条流水线，数据传入流水线经过一步步加工变换等按目标格式或输出（如改变为统一尺寸、随机旋转、数据标准化等）
- batch_size大一点效果可能更好，但注意内存；
- 一般训练流程都是先在预加载模型基础上训练自己的层(全链接或其他新加的)，训练差不多了再把前面的层设置为True，从头训练。
- 个人测试发现预加载模型并不是官方准确率越高或者版本越新就越好，还是和案例本身有关系，只能说多试。





# 2.Convolution Neural Network

## 1.conv

### 2.1doubts

1. 加法存在的不同情况下最终值相同问题：卷积的时候的相加和多通道的时候三个通道的相加，感觉对于任意不同的两张图片计算得出上面两个值相近的概率并不是很低，那么这就可以进一步导致不同图片识别为同一结果...虽然现在conv很成功准确率很高，但还是不太明白这里直接做加法是怎么保证能提取出特征的...
2. 计算$\omega$？



### 2.2 fundamental

1. 单channel 单卷积核![image-20220803123032687](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220803123032687.png)

   大部分图像为RGB三通道，因此要三个channel分别做如上卷积，即卷积核为三维的，将计算出的三个矩相加（**疑问**），再加上偏置矩阵，得到一个特征图。

2. 用多个不同卷积核得到多个不同特征图

   ![image-20220803123436100](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220803123436100.png)

   这样可以得到更丰富的特征；多个特征图的处理方法为并列（合并为三维，第三维称特征图的深度，即特征图的个数）。

3. 卷积层的堆叠![image-20220803124109044](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220803124109044.png)

   逐步提取出更高一级的特征；注意卷积核的第三维要与输入值的第三维(数据的通道数或前一个特征图的深度)相同
   
4. 卷积结果的大小

   ![image-20220805115813341](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220805115813341.png)

5. 卷积核参数共享

   为减小数据量和过拟合风险并提高训练效率，对于一张图的各个区域，用**同一组**卷积核进行卷积操作，如有10个5×5×3的卷积核，则仅需要5×5×3×10+10=760个权重参数，相较于全链接神经网络的参数量大幅减少。

### 2.3.some parameters

1. 步长![image-20220803181949698](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220803181949698.png)

   小-特征图大/特征丰富；大则相反，很好理解。

   图像处理任务步长通常**取1**

2. 卷积核尺寸

   很好理解，和步长特点一样，通常**最小取3*3**
   
3. 边缘填充padding

   靠近边缘处的像素点参与卷积的次数较少，靠近中心处的参与次数较多，这会导致数据利用不均等，因此常在数据边缘补几层0(0做乘法时不会影响结果，称zero padding)，通常补**1层**就行。

   这样可以在一定程度上弥补边界信息利用不充分的情况。

   padding也可用于填补大小不同的数据使之大小相同，如长度不同的文本数据。![image-20220805115537104](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220805115537104.png)

4. 卷积核个数

   自由确定，可参考一些经典网络的构建。





## 2.pooling

池化，对数据进行压缩(或称下采样-undersample/downsample)。

1. 池化操作通常在得到的原始特征基础上进行筛选，如多次卷积后进行池化，在筛选出重要特征的同时减少数据量。

2. 仅改变数据的长和宽，不能改变第三维；仅仅是筛选，不涉及复杂计算。
3. 现阶段的池化操作基本都是max pooling：指定选择区域的大小，在每个区域选出最大的值(通常数值大代表重要，则实现了依据重要性对特征的进一步筛选)。

![image-20220805221049848](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220805221049848.png)





## 3.the net

1. 一个卷积层(conv)后面通常跟着一个激活层(relu)；通常两次卷积后进行一次池化；最后是一个全连接层(fc)进行输出。![image-20220805222050580](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220805222050580.png)

2. 注意，带参数计算的层才能称为神经网络的层，如conv、fc，relu和pool则不称“层”，上图即为7层CNN。

3. 比较经典的CNN网络为2014年的vgg：![image-20220805223545089](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220805223545089.png)

   卷积核为3×3的；在每次池化后，使卷积特征图的个数增加一倍；经典版本为16层；训练时长以天为单位。

4. resnet-残差网络

   由于普通的神经网络在堆叠至20层以上后，准确率开始下降(因为学习到的特征可能不如之前)。

   简单来说，resnet给每几层网络添加了一条“保底路径”，即若经过接下来几层训练后的error相较于不训练更高，则直接“跳过”这几层(设置权重为0)，(感觉有点像预剪枝...)，这样可以保证随着层数升高，误差只减不增。因此resnet为当下更常用的网络。
   
5. sofrmax

   该层将各个输出节点的输出值范围映射到[0, 1]，并且约束各个输出节点的输出值的和为1，即归一化使得多分类的概率之和为1。







# 3.CV

## 3.1

1. data augmentation数据增强

   在图片数据量不够的情况下，可通过将图片进行旋转、对称、放缩、截取等操作得到多个图片，而这些图片无疑是同一类别的。

   ![image-20220809094036089](C:\Users\13950\AppData\Roaming\Typora\typora-user-images\image-20220809094036089.png)

2. transfer learning迁移学习

   在处理实际问题时，自己从头开始训练会遇到数据量不够、调参成本过高等问题，此时可直接使用他人已训练好的模型和参数，也可以在这基础上进行一定改动，通常为后者。

   同时官方的模型通常是经过大量实验得出并被大家认可的，所以这样不仅可以在一定程度上防止过拟合，还可以加快收敛速度、提高学习效率。

   当数据量较少时，可选择使用较大部分官方提供的网络层和参数，自己增加、修改一小部分；数据量大时则相反。当然具体要根据任务差异而定（如官方的是动物，具体任务是植物，那还是要改很多）





TODO：

改lr策略

其他模型

